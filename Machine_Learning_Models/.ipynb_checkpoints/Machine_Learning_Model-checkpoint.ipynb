{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from path import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = Path('../Baseball/Final_Game_Data_2019.csv')\n",
    "dataframe = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.strptime(\"2019-09-28\", \"%Y-%m-%d\")\n",
    "end = start - timedelta(7)\n",
    "date_generated = [start - timedelta(days=x) for x in range(0, (start-end).days)]\n",
    "dates = [date.strftime(\"%Y-%m-%d\") for date in date_generated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-09-27',\n",
       " '2019-09-26',\n",
       " '2019-09-25',\n",
       " '2019-09-24',\n",
       " '2019-09-23',\n",
       " '2019-09-22']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run random forest to determine the stats that contribute most to a win\n",
    " # Define features set\n",
    "X = dataframe.copy()\n",
    "X = X.drop(columns = ['G', 'G_Pitch'])\n",
    "y = dataframe.reset_index()[['Win Loss', 'Game Date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "accuracy_list = []\n",
    "X_df = pd.DataFrame()\n",
    "y_df = pd.DataFrame()\n",
    "length = len(dates[1:])\n",
    "for i in range(length + 1):\n",
    "    X_data = X.groupby('Game Date').get_group(dates[i])\n",
    "    X_df.append(X_data)\n",
    "    y_data = y.reset_index().groupby('Game Date').get_group(dates[i])['Win Loss']\n",
    "    y_df.append(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-176a891883d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mrf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Fitting the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mrf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Making predictions using the testing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    548\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[1;32m--> 550\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "for x in range(30):\n",
    "    X_train = X_df\n",
    "    X_test = X.groupby('Game Date').get_group(dates[0])\n",
    "    y_train = y_df\n",
    "    y_test = y.groupby('Game Date').get_group(dates[0])\n",
    "    # Create a random forest classifier\n",
    "    rf_model = RandomForestClassifier(n_estimators=8000, random_state = x)\n",
    "    # Fitting the model\n",
    "    rf_model = rf_model.fit(X_train, y_train)\n",
    "    # Making predictions using the testing data\n",
    "    predictions = rf_model.predict(X_test)\n",
    "    # Calculating the confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    "    )\n",
    "\n",
    "    # Calculating the accuracy score\n",
    "    acc_score = accuracy_score(y_test, predictions)\n",
    "    print(acc_score)\n",
    "    accuracy_list.append(acc_score)\n",
    "# Displaying results\n",
    "print(accuracy_list)\n",
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "# We can sort the features by their importance\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.6\n",
      "0.6\n",
      "0.6\n",
      "0.6\n",
      "0.5333333333333333\n",
      "0.6\n",
      "0.5333333333333333\n",
      "0.6\n",
      "0.6\n",
      "[0.6, 0.6, 0.6, 0.6, 0.6, 0.5333333333333333, 0.6, 0.5333333333333333, 0.6, 0.6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.04756772402687548, 'SH'),\n",
       " (0.03607304184288307, 'SF'),\n",
       " (0.03268875627566623, '3B'),\n",
       " (0.031005876751176928, 'BAbip_Pitch'),\n",
       " (0.03048595460708436, 'BA'),\n",
       " (0.02828281658013993, 'PA'),\n",
       " (0.028000720065794737, 'SLG'),\n",
       " (0.027575685939596438, 'BB'),\n",
       " (0.027163072292456642, 'R'),\n",
       " (0.026422569727107523, 'SO_Pitch'),\n",
       " (0.02565579261069881, 'LD_Pitch'),\n",
       " (0.025155654015331465, 'PU_Pitch'),\n",
       " (0.024827398230082866, 'GB/FB_Pitch'),\n",
       " (0.02475254850607259, 'Str_Pitch'),\n",
       " (0.023910369820910223, 'WHIP_Pitch'),\n",
       " (0.023498671740812944, 'StL_Pitch'),\n",
       " (0.023371998274159155, 'OPS'),\n",
       " (0.023174523534633343, 'ERA_Pitch'),\n",
       " (0.02260862748471391, 'GDP'),\n",
       " (0.021401462868960483, 'CS'),\n",
       " (0.021014720319770495, 'Pit_Pitch'),\n",
       " (0.020957353172783293, 'HR'),\n",
       " (0.019857569914950975, 'Unnamed: 0'),\n",
       " (0.01980153866961722, 'SO9_Pitch'),\n",
       " (0.019727201625470373, 'AB'),\n",
       " (0.019299099334540885, 'SO'),\n",
       " (0.018456368088462457, '2B'),\n",
       " (0.0183969697441473, 'SB'),\n",
       " (0.018338765160673075, 'HBP'),\n",
       " (0.017720371913349013, 'AB_Pitch'),\n",
       " (0.017511780870014287, 'BB_Pitch'),\n",
       " (0.01722007427228994, 'StS_Pitch'),\n",
       " (0.017038877095375982, 'RBI'),\n",
       " (0.016817280487932667, 'IBB'),\n",
       " (0.016743900378007374, 'OBP'),\n",
       " (0.016474309132640207, 'HR_Pitch'),\n",
       " (0.015537676640706715, 'BF_Pitch'),\n",
       " (0.014798684069721927, 'H'),\n",
       " (0.014625735274110015, '2B_Pitch'),\n",
       " (0.013240833611275668, 'R_Pitch'),\n",
       " (0.012393471049969683, 'ER_Pitch'),\n",
       " (0.01195722530180165, 'H_Pitch'),\n",
       " (0.008912337079616422, 'GS_Pitch'),\n",
       " (0.008755208888137416, 'SF_Pitch'),\n",
       " (0.008497313133401562, 'HBP_Pitch'),\n",
       " (0.00849658318160213, '3B_Pitch'),\n",
       " (0.008475806843307303, 'SB_Pitch'),\n",
       " (0.008049301928911413, 'GDP_Pitch'),\n",
       " (0.007978008117856292, 'CS_Pitch'),\n",
       " (0.005457765850647252, 'IBB_Pitch'),\n",
       " (0.0038246036537519313, 'PO_Pitch')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run random forest to determine the stats that contribute most to a win\n",
    " # Define features set\n",
    "X = dataframe.copy()\n",
    "X = X.drop(columns = ['G', 'G_Pitch', 'Game Date', 'Tm', 'Opponent', 'Win Loss'])\n",
    "y = dataframe.reset_index()['Win Loss']\n",
    "# Splitting into Train and Test sets\n",
    "accuracy_list = []\n",
    "for x in range(10):\n",
    "    X_train = X[-90:-15]\n",
    "    X_test = X[-15:]\n",
    "    y_train = y[-90:-15]\n",
    "    y_test = y[-15:]\n",
    "    # Create a random forest classifier\n",
    "    rf_model = RandomForestClassifier(n_estimators=8000, random_state = x)\n",
    "    # Fitting the model\n",
    "    rf_model = rf_model.fit(X_train, y_train)\n",
    "    # Making predictions using the testing data\n",
    "    predictions = rf_model.predict(X_test)\n",
    "    # Calculating the confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    cm_df = pd.DataFrame(\n",
    "        cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    "    )\n",
    "\n",
    "    # Calculating the accuracy score\n",
    "    acc_score = accuracy_score(y_test, predictions)\n",
    "    print(acc_score)\n",
    "    accuracy_list.append(acc_score)\n",
    "# Displaying results\n",
    "print(accuracy_list)\n",
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "# We can sort the features by their importance\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
